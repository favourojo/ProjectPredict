{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac94724-2c73-41cf-b5f2-42145b62e217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not_fully_funded\n",
      "0    430683\n",
      "1    188643\n",
      "Name: count, dtype: int64\n",
      "                          projectid is_exciting  not_fully_funded\n",
      "0  ffffc4f85b60efc5b52347df489d0238           f                 1\n",
      "1  ffffac55ee02a49d1abc87ba6fc61135           f                 0\n",
      "2  ffff97ed93720407d70a2787475932b0           f                 0\n",
      "3  ffff418bb42fad24347527ad96100f81           f                 1\n",
      "4  ffff2d9c769c8fb5335e949c615425eb           t                 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load outcomes.csv\n",
    "outcomes = pd.read_csv('outcomes.csv')\n",
    "\n",
    "# Convert 't' (True) → 1, 'f' (False) → 0\n",
    "outcomes['fully_funded'] = outcomes['fully_funded'].map({'t': 1, 'f': 0})\n",
    "outcomes['not_fully_funded'] = outcomes['fully_funded'].apply(lambda x: 0 if x == 1 else 1)\n",
    "\n",
    "# Confirm the conversion\n",
    "print(outcomes['not_fully_funded'].value_counts())\n",
    "print(outcomes[['projectid','is_exciting', 'not_fully_funded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37f57a80-1505-40fa-9a62-ef679e8caaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = pd.read_csv('projects.csv')\n",
    "data = pd.merge(projects, outcomes[['projectid', 'not_fully_funded']], on='projectid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64a0ab0b-3910-442b-a6ca-9547b812030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['primary_focus_subject', 'school_state', 'resource_type', 'poverty_level']  # example\n",
    "X = data[features]\n",
    "y = data['not_fully_funded']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fabea86-77f6-44a8-809c-110092287506",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8ae0e70-60f1-4bc4-8d61-8e9c92f91021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert and filter by date\n",
    "data['date_posted'] = pd.to_datetime(data['date_posted'])\n",
    "data = data[data['date_posted'] >= '2010-01-01']\n",
    "\n",
    "# Sort chronologically\n",
    "data = data.sort_values('date_posted')\n",
    "\n",
    "# Temporal 80/20 split\n",
    "cutoff = int(len(data) * 0.8)\n",
    "train = data.iloc[:cutoff]\n",
    "test = data.iloc[cutoff:]\n",
    "\n",
    "# Extract features and target\n",
    "X_train = train[features]\n",
    "y_train = train['not_fully_funded']\n",
    "X_test = test[features]\n",
    "y_test = test['not_fully_funded']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd6fdade-7704-4e88-9f36-2db4b0e4bf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.55082912 0.5678521  0.57615953 0.59639123 0.60850119]\n",
      "Average accuracy: 0.5799466341111341\n",
      "Cross-validation precision scores: [0.35634987 0.36165108 0.37281948 0.39147671 0.4013563 ]\n",
      "Average precision: 0.37673068863406584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Step 1: Instantiate the model\n",
    "model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Step 2: Define metrics\n",
    "scoring = ['accuracy', 'precision']\n",
    "\n",
    "# Step 3: Run 5-fold cross-validation\n",
    "cv_results = cross_validate(model, X, y, cv=5, scoring=scoring)\n",
    "\n",
    "# Step 4: Output results\n",
    "print(\"Cross-validation accuracy scores:\", cv_results['test_accuracy'])\n",
    "print(\"Average accuracy:\", cv_results['test_accuracy'].mean())\n",
    "\n",
    "print(\"Cross-validation precision scores:\", cv_results['test_precision'])\n",
    "print(\"Average precision:\", cv_results['test_precision'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4bc854d-cf73-4bff-bfe0-fd8777f3b63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83     62713\n",
      "           1       0.44      0.03      0.06     25207\n",
      "\n",
      "    accuracy                           0.71     87920\n",
      "   macro avg       0.58      0.51      0.44     87920\n",
      "weighted avg       0.64      0.71      0.61     87920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Predict probabilities\n",
    "y_probs = model.predict_proba(X_test)[:, 1]  # probability of class 1\n",
    "\n",
    "# 2. Apply a custom threshold (e.g., 0.7 instead of 0.5)\n",
    "y_pred_custom = (y_probs >= 0.7).astype(int)\n",
    "\n",
    "# 3. Evaluate\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_custom))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e7b51aa-f60b-4463-8ba4-08d4c8d49a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.43      0.56     62713\n",
      "           1       0.34      0.71      0.46     25207\n",
      "\n",
      "    accuracy                           0.51     87920\n",
      "   macro avg       0.56      0.57      0.51     87920\n",
      "weighted avg       0.66      0.51      0.53     87920\n",
      "\n",
      "Confusion Matrix:\n",
      "[[27267 35446]\n",
      " [ 7295 17912]]\n",
      "Precision Score: 0.3356947411822032\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, precision_score, confusion_matrix\n",
    "\n",
    "# 1. Handle missing values (if any)\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# 2. One-hot encode categorical features, if not already done\n",
    "X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "\n",
    "# 3. Align test set to training set (same columns)\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# 4. Check for any NaNs or bad types again\n",
    "assert X_train.isnull().sum().sum() == 0, \"NaNs in X_train\"\n",
    "assert X_test.isnull().sum().sum() == 0, \"NaNs in X_test\"\n",
    "\n",
    "# 5. Instantiate logistic regression model\n",
    "model = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "\n",
    "# 6. Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 7. Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 8. Evaluate performance\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Precision Score:\", precision_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f24adc3-47c3-4ca4-b701-cbea213ed097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83     62713\n",
      "           1       0.44      0.03      0.06     25207\n",
      "\n",
      "    accuracy                           0.71     87920\n",
      "   macro avg       0.58      0.51      0.44     87920\n",
      "weighted avg       0.64      0.71      0.61     87920\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9881930d-f96a-4005-8081-535d41863779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac5389bf-d890-4f4b-8db3-5e5ed075ba8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-3.0.0-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.13.1)\n",
      "Using cached xgboost-3.0.0-py3-none-macosx_12_0_arm64.whl (2.0 MB)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d95e1f9-d349-4d8d-acc7-4c84dc7250e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.0\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "print(xgboost.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eab8a660-e97e-4306-a567-9e65b8945fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [19:16:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.46      0.58     62713\n",
      "           1       0.34      0.69      0.46     25207\n",
      "\n",
      "    accuracy                           0.53     87920\n",
      "   macro avg       0.56      0.58      0.52     87920\n",
      "weighted avg       0.66      0.53      0.55     87920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = XGBClassifier(\n",
    "    scale_pos_weight=(y == 0).sum() / (y == 1).sum(),  # class balancing\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "647fdd4d-45e7-474a-8d69-068a2b810aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best precision score from GridSearchCV: 0.3612609004346249\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10, None]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    param_grid=params,\n",
    "    scoring='precision',  # prioritize precision\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Use best model from search\n",
    "model = grid.best_estimator_\n",
    "print(\"Best precision score from GridSearchCV:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990dd772-a455-4c75-90a5-8ab79b96d318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
