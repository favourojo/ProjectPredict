{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ac94724-2c73-41cf-b5f2-42145b62e217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not_fully_funded\n",
      "0    430683\n",
      "1    188643\n",
      "Name: count, dtype: int64\n",
      "                          projectid is_exciting  not_fully_funded\n",
      "0  ffffc4f85b60efc5b52347df489d0238           f                 1\n",
      "1  ffffac55ee02a49d1abc87ba6fc61135           f                 0\n",
      "2  ffff97ed93720407d70a2787475932b0           f                 0\n",
      "3  ffff418bb42fad24347527ad96100f81           f                 1\n",
      "4  ffff2d9c769c8fb5335e949c615425eb           t                 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load outcomes.csv\n",
    "outcomes = pd.read_csv('outcomes.csv')\n",
    "\n",
    "# Convert 't' (True) → 1, 'f' (False) → 0\n",
    "outcomes['fully_funded'] = outcomes['fully_funded'].map({'t': 1, 'f': 0})\n",
    "outcomes['not_fully_funded'] = outcomes['fully_funded'].apply(lambda x: 0 if x == 1 else 1)\n",
    "\n",
    "# Confirm the conversion\n",
    "print(outcomes['not_fully_funded'].value_counts())\n",
    "print(outcomes[['projectid','is_exciting', 'not_fully_funded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37f57a80-1505-40fa-9a62-ef679e8caaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = pd.read_csv('projects.csv')\n",
    "data = pd.merge(projects, outcomes[['projectid', 'not_fully_funded']], on='projectid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64a0ab0b-3910-442b-a6ca-9547b812030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['primary_focus_subject', 'school_state', 'resource_type', 'poverty_level']  # example\n",
    "X = data[features]\n",
    "y = data['not_fully_funded']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fabea86-77f6-44a8-809c-110092287506",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8ae0e70-60f1-4bc4-8d61-8e9c92f91021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert and filter by date\n",
    "data['date_posted'] = pd.to_datetime(data['date_posted'])\n",
    "data = data[data['date_posted'] >= '2010-01-01']\n",
    "\n",
    "# Sort chronologically\n",
    "data = data.sort_values('date_posted')\n",
    "\n",
    "# Temporal 80/20 split\n",
    "cutoff = int(len(data) * 0.8)\n",
    "train = data.iloc[:cutoff]\n",
    "test = data.iloc[cutoff:]\n",
    "\n",
    "# Extract features and target\n",
    "X_train = train[features]\n",
    "y_train = train['not_fully_funded']\n",
    "X_test = test[features]\n",
    "y_test = test['not_fully_funded']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd6fdade-7704-4e88-9f36-2db4b0e4bf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.55082912 0.5678521  0.57615953 0.59639123 0.60850119]\n",
      "Average accuracy: 0.5799466341111341\n",
      "Cross-validation precision scores: [0.35634987 0.36165108 0.37281948 0.39147671 0.4013563 ]\n",
      "Average precision: 0.37673068863406584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Step 1: Instantiate the model\n",
    "model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Step 2: Define metrics\n",
    "scoring = ['accuracy', 'precision']\n",
    "\n",
    "# Step 3: Run 5-fold cross-validation\n",
    "cv_results = cross_validate(model, X, y, cv=5, scoring=scoring)\n",
    "\n",
    "# Step 4: Output results\n",
    "print(\"Cross-validation accuracy scores:\", cv_results['test_accuracy'])\n",
    "print(\"Average accuracy:\", cv_results['test_accuracy'].mean())\n",
    "\n",
    "print(\"Cross-validation precision scores:\", cv_results['test_precision'])\n",
    "print(\"Average precision:\", cv_results['test_precision'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4bc854d-cf73-4bff-bfe0-fd8777f3b63e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 1. Predict probabilities\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y_probs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# probability of class 1\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 2. Apply a custom threshold (e.g., 0.7 instead of 0.5)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m y_pred_custom \u001b[38;5;241m=\u001b[39m (y_probs \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.7\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:945\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    924\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;124;03m    Predict class probabilities for X.\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;124;03m        classes corresponds to that in the attribute :term:`classes_`.\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 945\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m    947\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1622\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1619\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[1;32m   1621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m-> 1622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# 1. Predict probabilities\n",
    "y_probs = model.predict_proba(X_test)[:, 1]  # probability of class 1\n",
    "\n",
    "# 2. Apply a custom threshold (e.g., 0.7 instead of 0.5)\n",
    "y_pred_custom = (y_probs >= 0.7).astype(int)\n",
    "\n",
    "# 3. Evaluate\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_custom))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e7b51aa-f60b-4463-8ba4-08d4c8d49a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.43      0.56     62713\n",
      "           1       0.34      0.71      0.46     25207\n",
      "\n",
      "    accuracy                           0.51     87920\n",
      "   macro avg       0.56      0.57      0.51     87920\n",
      "weighted avg       0.66      0.51      0.53     87920\n",
      "\n",
      "Confusion Matrix:\n",
      "[[27267 35446]\n",
      " [ 7295 17912]]\n",
      "Precision Score: 0.3356947411822032\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, precision_score, confusion_matrix\n",
    "\n",
    "# 1. Handle missing values (if any)\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# 2. One-hot encode categorical features, if not already done\n",
    "X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "\n",
    "# 3. Align test set to training set (same columns)\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# 4. Check for any NaNs or bad types again\n",
    "assert X_train.isnull().sum().sum() == 0, \"NaNs in X_train\"\n",
    "assert X_test.isnull().sum().sum() == 0, \"NaNs in X_test\"\n",
    "\n",
    "# 5. Instantiate logistic regression model\n",
    "model = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "\n",
    "# 6. Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 7. Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 8. Evaluate performance\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Precision Score:\", precision_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f24adc3-47c3-4ca4-b701-cbea213ed097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881930d-f96a-4005-8081-535d41863779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5389bf-d890-4f4b-8db3-5e5ed075ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d95e1f9-d349-4d8d-acc7-4c84dc7250e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "print(xgboost.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eab8a660-e97e-4306-a567-9e65b8945fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [13:36:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.46      0.58     62713\n",
      "           1       0.34      0.69      0.46     25207\n",
      "\n",
      "    accuracy                           0.53     87920\n",
      "   macro avg       0.56      0.58      0.52     87920\n",
      "weighted avg       0.66      0.53      0.55     87920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = XGBClassifier(\n",
    "    scale_pos_weight=(y == 0).sum() / (y == 1).sum(),  # class balancing\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647fdd4d-45e7-474a-8d69-068a2b810aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10, None]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    param_grid=params,\n",
    "    scoring='precision',  # prioritize precision\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Use best model from search\n",
    "model = grid.best_estimator_\n",
    "print(\"Best precision score from GridSearchCV:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990dd772-a455-4c75-90a5-8ab79b96d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define search space\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],      # number of trees\n",
    "    'max_depth': [5, 10, 20, None],       # tree depth\n",
    "    'min_samples_split': [2, 5, 10],      # min split\n",
    "    'min_samples_leaf': [1, 2, 4],        # min leaf\n",
    "    'max_features': ['sqrt', 'log2'],     # feature selection\n",
    "}\n",
    "\n",
    "# Instantiate model\n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Grid search, scoring on precision\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    scoring='precision',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Use best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Predict and evaluate\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = best_rf.predict(X_test)\n",
    "print(\"Best precision score from CV:\", grid_search.best_score_)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffebcfac-4ec5-4c3f-8d6d-5577583b72e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
