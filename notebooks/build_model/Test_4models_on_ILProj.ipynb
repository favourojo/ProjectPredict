{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score, precision_score\n"
      ],
      "metadata": {
        "id": "XZaafpQhScv5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data\n",
        "outcomes = pd.read_csv('outcomes.csv')\n",
        "projects = pd.read_csv('projects.csv')\n",
        "\n",
        "outcomes['fully_funded'] = outcomes['fully_funded'].map({'t': 1, 'f': 0})\n",
        "outcomes['not_fully_funded'] = 1 - outcomes['fully_funded']\n",
        "projects['date_posted'] = pd.to_datetime(projects['date_posted'])\n",
        "data = pd.merge(projects, outcomes[['projectid', 'not_fully_funded']], on='projectid')\n",
        "\n",
        "data = data[data['date_posted'] >= '2010-01-01']  # Only use data after 2010\n",
        "data_chicago = data[data['school_state'] == 'IL']  # Only look at the state IL\n",
        "data_chicago_dropped = data_chicago.drop(columns=[\n",
        "    'secondary_focus_subject', 'secondary_focus_area', 'school_metro',\n",
        "    'school_ncesid', 'school_latitude', 'school_longitude'\n",
        "])\n",
        "\n",
        "# Create feature list and split data\n",
        "features = [\n",
        "    'primary_focus_subject', 'resource_type', 'school_nlns', 'school_charter',\n",
        "    'school_county', 'school_district', 'teacher_prefix', 'poverty_level',\n",
        "    'grade_level', 'fulfillment_labor_materials',\n",
        "    'total_price_excluding_optional_support', 'total_price_including_optional_support'\n",
        "]\n",
        "\n",
        "X = data_chicago_dropped[features]\n",
        "y = data_chicago_dropped['not_fully_funded']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define preprocessing\n",
        "numeric_features = [\n",
        "    'fulfillment_labor_materials',\n",
        "    'total_price_excluding_optional_support',\n",
        "    'total_price_including_optional_support'\n",
        "]\n",
        "\n",
        "categorical_features = [\n",
        "    'primary_focus_subject', 'resource_type', 'school_nlns', 'school_charter',\n",
        "    'school_county', 'school_district', 'teacher_prefix', 'poverty_level', 'grade_level'\n",
        "]\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "])\n"
      ],
      "metadata": {
        "id": "0tGQbXctKmOw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=============================================================================\n",
        "# STEP 1: BASELINE PERFORMANCE WITH DEFAULT HYPERPARAMETERS (WITH TOP 10% PRECISION)\n",
        "============================================================================="
      ],
      "metadata": {
        "id": "YJzP2pqtWFSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.base import clone"
      ],
      "metadata": {
        "id": "9315wIdUWL-y"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define models without parameter grids (defaults only)\n",
        "baseline_models = [\n",
        "    ('Random Forest', RandomForestClassifier(random_state=42)),\n",
        "    ('KNN', KNeighborsClassifier()),\n",
        "    ('Decision Tree', DecisionTreeClassifier(random_state=42)),\n",
        "    ('Logistic Regression', LogisticRegression(random_state=42, max_iter=1000))\n",
        "]"
      ],
      "metadata": {
        "id": "D5oQ8-EjRxFZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "baseline_results = []"
      ],
      "metadata": {
        "id": "nNK1pYGARubT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, estimator in baseline_models:\n",
        "    print(f\"\\n{'='*40}\\nEvaluating {name} Baseline...\\n{'='*40}\")\n",
        "\n",
        "    # Create pipeline with default estimator\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', clone(estimator))  # Clone to avoid parameter leakage\n",
        "    ])\n",
        "\n",
        "    # Get predicted probabilities using cross-validation\n",
        "    y_proba = cross_val_predict(\n",
        "        estimator=pipeline,\n",
        "        X=X_train,\n",
        "        y=y_train,\n",
        "        cv=cv,\n",
        "        method='predict_proba',\n",
        "        n_jobs=-1,\n",
        "        verbose=1\n",
        "    )[:, 1]  # Get probabilities for class 1\n",
        "\n",
        "    # Calculate metrics using out-of-fold predictions\n",
        "    results_df = pd.DataFrame({'score': y_proba, 'true_label': y_train.reset_index(drop=True)})\n",
        "    results_df['rank'] = results_df['score'].rank(method='first', ascending=False)\n",
        "    top_10_percent_cutoff = int(len(results_df) * 0.1)\n",
        "    results_df['prediction'] = (results_df['rank'] <= top_10_percent_cutoff).astype(int)\n",
        "\n",
        "    # Calculate precision@top10%\n",
        "    precision_top10 = precision_score(\n",
        "        results_df['true_label'],\n",
        "        results_df['prediction'],\n",
        "        zero_division=0\n",
        "    )\n",
        "\n",
        "    # Store results\n",
        "    baseline_results.append({\n",
        "        'Model': name,\n",
        "        'ROC AUC (CV)': roc_auc_score(y_train, y_proba),\n",
        "        'PR AUC (CV)': average_precision_score(y_train, y_proba),\n",
        "        'Precision@Top10% (CV)': precision_top10\n",
        "    })\n",
        "\n",
        "# Display baseline results\n",
        "print(\"\\n\\n\" + \"=\"*40 + \"\\nBaseline Model Performance (Cross-Validated)\\n\" + \"=\"*40)\n",
        "baseline_df = pd.DataFrame(baseline_results)\n",
        "print(baseline_df.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_2US2G0Wp-q",
        "outputId": "ddbda1d2-8703-4ea5-fefa-5486014a4183"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "Evaluating Random Forest Baseline...\n",
            "========================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   55.9s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "Evaluating KNN Baseline...\n",
            "========================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.7s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "Evaluating Decision Tree Baseline...\n",
            "========================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "Evaluating Logistic Regression Baseline...\n",
            "========================================\n",
            "\n",
            "\n",
            "========================================\n",
            "Baseline Model Performance (Cross-Validated)\n",
            "========================================\n",
            "              Model  ROC AUC (CV)  PR AUC (CV)  Precision@Top10% (CV)\n",
            "      Random Forest      0.707357     0.420031               0.507366\n",
            "                KNN      0.634719     0.338714               0.430171\n",
            "      Decision Tree      0.570947     0.290138               0.362994\n",
            "Logistic Regression      0.688718     0.414557               0.496759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.1s finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, auc, roc_curve, roc_auc_score\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "gvO1rVQ5oZ13"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Findings: Precision@Top10% was the highest with Random Forest(0.507366) but Logistic Regression was a clost with (0.496759)**\n",
        "\n",
        "Now lets see if HYPERPARAMETER TUNING can help us."
      ],
      "metadata": {
        "id": "gRBu84NbXk4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "=============================================================================\n",
        "STEP 2: HYPERPARAMETER TUNING WITH GRIDSEARCH (ONLY FOR TOP MODELS)\n",
        "============================================================================="
      ],
      "metadata": {
        "id": "AZLGUCG8S2q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\n",
        "    {\n",
        "        'name': 'Random Forest',\n",
        "        'estimator': RandomForestClassifier(random_state=42),\n",
        "        'param_grid': {\n",
        "            'classifier__n_estimators': [50, 100, 150],\n",
        "            'classifier__max_depth': [5, 10, 15],\n",
        "            'classifier__min_samples_split': [2, 5, 10],\n",
        "            'classifier__min_samples_leaf': [1, 2],\n",
        "            'classifier__class_weight': ['balanced'],\n",
        "            'classifier__bootstrap': [True]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        'name': 'Logistic Regression',\n",
        "        'estimator': LogisticRegression(random_state=42, max_iter=1000),\n",
        "        'param_grid': {\n",
        "            'classifier__C': [0.05,0.1, 1, 10],\n",
        "            'classifier__solver': ['saga'],\n",
        "            'classifier__penalty': ['l1','l2', 'none'],\n",
        "            'classifier__class_weight': [None, 'balanced']\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# Train and evaluate tuned models\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "results = []\n",
        "\n",
        "for model in models:\n",
        "    print(f\"\\n{'='*40}\\nTraining {model['name']}...\\n{'='*40}\")\n",
        "\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', model['estimator'])\n",
        "    ])\n",
        "\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=pipeline,\n",
        "        param_grid=model['param_grid'],\n",
        "        cv=cv,\n",
        "        refit='PR_AUC',\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        scoring={\n",
        "            'accuracy': 'accuracy',\n",
        "            'precision': 'precision',\n",
        "            'recall': 'recall',\n",
        "            'f1': 'f1',\n",
        "            'roc_auc': 'roc_auc',\n",
        "            'PR_AUC': 'average_precision'\n",
        "        }\n",
        "    )\n",
        "\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get predictions on test set\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    y_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Calculate metrics (including top 10% precision)\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    results_df = pd.DataFrame({'score': y_proba, 'true_label': y_test.reset_index(drop=True)})\n",
        "    results_df['rank'] = results_df['score'].rank(method='first', ascending=False)\n",
        "    top_10_percent_cutoff = int(len(results_df) * 0.1)\n",
        "    results_df['prediction'] = (results_df['rank'] <= top_10_percent_cutoff).astype(int)\n",
        "\n",
        "    results.append({\n",
        "        'Model': model['name'],\n",
        "        'Best Params': grid_search.best_params_,\n",
        "        'Test Accuracy': report['accuracy'],\n",
        "        'Test Precision (Class 1)': report['1']['precision'],\n",
        "        'Test Recall (Class 1)': report['1']['recall'],\n",
        "        'Test F1 (Class 1)': report['1']['f1-score'],\n",
        "        'Test ROC AUC': roc_auc_score(y_test, y_proba),\n",
        "        'Test PR AUC': average_precision_score(y_test, y_proba),\n",
        "        'Test Precision Top10%': precision_score(results_df['true_label'], results_df['prediction'])\n",
        "    })\n",
        "\n",
        "# Display final results\n",
        "print(\"\\n\\n\" + \"=\"*40 + \"\\nFinal Model Comparison (Tuned)\\n\" + \"=\"*40)\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nMetrics Comparison:\")\n",
        "print(results_df.drop(columns='Best Params').to_string(index=False))\n",
        "print(\"\\n\\n\" + \"=\"*40 + \"\\nBest Parameters\\n\" + \"=\"*40)\n",
        "for model_result in results:\n",
        "    print(f\"\\n{model_result['Model']}:\")\n",
        "    print(pd.Series(model_result['Best Params']).to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBiPBGfXdgb_",
        "outputId": "41674d3d-81c6-4cb0-d263-3bc82ea8b381"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "Training Random Forest...\n",
            "========================================\n",
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
            "\n",
            "========================================\n",
            "Training Logistic Regression...\n",
            "========================================\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "40 fits failed out of a total of 120.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "21 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 662, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "19 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 662, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'none' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.74988221 0.74952866        nan 0.65230933 0.65932113        nan\n",
            " 0.7504124  0.75088378        nan 0.6544894  0.66091193        nan\n",
            " 0.75164991 0.75111954        nan 0.66150082 0.66385778        nan\n",
            " 0.75200328 0.75164975        nan 0.66403453 0.66432917        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.54259217 0.52053386        nan 0.38309274 0.38954432        nan\n",
            " 0.54642271 0.53678337        nan 0.38535045 0.39050066        nan\n",
            " 0.5358744  0.5246836         nan 0.39008497 0.39111526        nan\n",
            " 0.53041448 0.52723174        nan 0.39098829 0.39113232        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.03957845 0.0557377         nan 0.62412178 0.62318501        nan\n",
            " 0.04847775 0.07213115        nan 0.62576112 0.61943794        nan\n",
            " 0.09929742 0.11217799        nan 0.61194379 0.6030445         nan\n",
            " 0.12271663 0.12248244        nan 0.60117096 0.6               nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.07371115 0.10068764        nan 0.4746214  0.47926577        nan\n",
            " 0.08902197 0.12713984        nan 0.47681291 0.47890539        nan\n",
            " 0.16736593 0.18472259        nan 0.47634257 0.47440178        nan\n",
            " 0.1992377  0.19870105        nan 0.47372255 0.47346032        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.67815466 0.6904531         nan 0.69074119 0.69936314        nan\n",
            " 0.68685957 0.6918887         nan 0.69710524 0.70041241        nan\n",
            " 0.69400417 0.69139796        nan 0.70162901 0.69843641        nan\n",
            " 0.6909596  0.69044107        nan 0.6976005  0.69706409        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.39867159 0.41534606        nan 0.41104768 0.42327112        nan\n",
            " 0.41003564 0.41860027        nan 0.42031053 0.42592409        nan\n",
            " 0.42194526 0.41821094        nan 0.42930191 0.42504071        nan\n",
            " 0.41770463 0.41701988        nan 0.42402721 0.42346304        nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "========================================\n",
            "Final Model Comparison (Tuned)\n",
            "========================================\n",
            "\n",
            "Metrics Comparison:\n",
            "              Model  Test Accuracy  Test Precision (Class 1)  Test Recall (Class 1)  Test F1 (Class 1)  Test ROC AUC  Test PR AUC  Test Precision Top10%\n",
            "      Random Forest       0.663210                  0.401724               0.643054           0.494517      0.714277     0.459238               0.556604\n",
            "Logistic Regression       0.658025                  0.393443               0.618215           0.480859      0.702084     0.447423               0.530660\n",
            "\n",
            "\n",
            "========================================\n",
            "Best Parameters\n",
            "========================================\n",
            "\n",
            "Random Forest:\n",
            "classifier__bootstrap                True\n",
            "classifier__class_weight         balanced\n",
            "classifier__max_depth                  15\n",
            "classifier__min_samples_leaf            1\n",
            "classifier__min_samples_split           5\n",
            "classifier__n_estimators              100\n",
            "\n",
            "Logistic Regression:\n",
            "classifier__C                      1\n",
            "classifier__class_weight    balanced\n",
            "classifier__penalty               l1\n",
            "classifier__solver              saga\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.savefig('confusion_matrix.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "jTn-zQUyn0aX",
        "outputId": "382c0689-60f3-4a29-ea0d-d895f698726f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}