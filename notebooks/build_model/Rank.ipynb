{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407e5c08-0974-4c0e-aa4d-1137d57e7db0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.pipeline import Pipeline  \n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Step 1: Load and preprocess data\n",
    "outcomes = pd.read_csv('outcomes.csv')\n",
    "projects = pd.read_csv('projects.csv')\n",
    "donations = pd.read_csv('donations.csv')\n",
    "\n",
    "# Map 't' → 1 and 'f' → 0 in 'fully_funded'\n",
    "outcomes['fully_funded'] = outcomes['fully_funded'].map({'t': 1, 'f': 0})\n",
    "outcomes['not_fully_funded'] = 1 - outcomes['fully_funded']  # Alternative to lambda\n",
    "\n",
    "# Merge datasets and filter by date\n",
    "projects['date_posted'] = pd.to_datetime(projects['date_posted'])\n",
    "\n",
    "# Merge datasets\n",
    "data = projects.merge(outcomes, on='projectid', how='inner').merge(\n",
    "    donations[['projectid', 'donation_timestamp', 'donation_total']], on='projectid', how='left')\n",
    "\n",
    "# Define feature types\n",
    "numeric_features = ['students_reached', 'total_price_excluding_optional_support', 'donation_total']\n",
    "categorical_features = ['primary_focus_subject', 'resource_type', 'primary_focus_area']\n",
    "\n",
    "# ✅ **Define Transformations (Place Before Model Pipeline!)**\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# ✅ **Now Create Model Pipeline (After Defining Preprocessor!)**\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LogisticRegression(max_iter=500, solver='liblinear', random_state=42))\n",
    "])\n",
    "\n",
    "# Train model\n",
    "X_train = data[numeric_features + categorical_features]\n",
    "y_train = data['fully_funded']\n",
    "\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "data = data[data['date_posted'] >= '2010-01-01']\n",
    "\n",
    "# Confirm the conversion\n",
    "print(outcomes['not_fully_funded'].value_counts())\n",
    "print(outcomes[['projectid','is_exciting', 'not_fully_funded']].head())\n",
    "\n",
    "# Add new time-related features \n",
    "data['year_posted'] = data['date_posted'].dt.year\n",
    "data['month_posted'] = data['date_posted'].dt.month\n",
    "data['days_since_posted'] = (pd.Timestamp.now() - data['date_posted']).dt.days\n",
    "\n",
    "# Add interaction features\n",
    "data['state_poverty_interaction'] = data['school_state'] + '_' + data['poverty_level']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dfba26-34cc-46e1-9eb1-cfc8835c0193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Minimal feature matrix\n",
    "features = [\n",
    "    'primary_focus_subject', \n",
    "    'school_state', \n",
    "    'resource_type', \n",
    "    'poverty_level',\n",
    "    'year_posted',\n",
    "    'month_posted',\n",
    "    'days_since_posted',\n",
    "    'state_poverty_interaction'\n",
    "]\n",
    "X = pd.get_dummies(data[features], drop_first=True)\n",
    "y = data['not_fully_funded']\n",
    "\n",
    "# Step 3: Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.80, random_state=42)\n",
    "\n",
    "# Step 4: Train model and predict probabilities\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "# Step 5: Rank probabilities and calculate precision\n",
    "results_df = pd.DataFrame({'score': y_proba})\n",
    "results_df['rank'] = results_df['score'].rank(method='first', ascending=False)\n",
    "\n",
    "# Label top 10% as 1 and calculate precision\n",
    "top_10_percent_cutoff = int(len(results_df) * 0.1)\n",
    "results_df['prediction'] = (results_df['rank'] <= top_10_percent_cutoff).astype(int)\n",
    "precision = precision_score(y_test, results_df['prediction'])\n",
    "\n",
    "# Output results\n",
    "print(f\"Precision for top 10%: {precision}\")\n",
    "print(results_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5860a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Replace RandomForest with Logistic Regression\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LogisticRegression(max_iter=500, solver='liblinear', random_state=42))\n",
    "])\n",
    "\n",
    "# Train model\n",
    "X_train = data[numeric_features + categorical_features]\n",
    "y_train = data['fully_funded']\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Get probabilities for ranking\n",
    "y_proba = model_pipeline.predict_proba(X_train)[:, 1]  # Extract probability of being fully funded\n",
    "results_df = pd.DataFrame({'score': y_proba})\n",
    "results_df['rank'] = results_df['score'].rank(method='first', ascending=False)\n",
    "\n",
    "# Define the top 10% threshold for precision calculation\n",
    "top_10_percent_cutoff = int(len(results_df) * 0.1)\n",
    "results_df['prediction'] = (results_df['rank'] <= top_10_percent_cutoff).astype(int)\n",
    "\n",
    "# Calculate precision\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_train, results_df['prediction'])\n",
    "\n",
    "# Output results\n",
    "print(f\"Precision for top 10%: {precision}\")\n",
    "print(results_df.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1558d74-bf03-4908-b5d2-998fb988a760",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 5: Rank probabilities and calculate precision\n",
    "results_df = pd.DataFrame({\n",
    "    'projectid': data.loc[X_test.index, 'projectid'], # Match project ID from data_sample\n",
    "    'score': y_proba # Predicted probability of not getting funded\n",
    "})\n",
    "# Sort by score in descending order\n",
    "results_df = results_df.sort_values(by='score', ascending=False)\n",
    "\n",
    "# Assign rank based on score order \n",
    "results_df['rank'] = results_df['score'].rank(method='first', ascending=False)\n",
    "\n",
    "# Label top 10% as needing review \n",
    "threshold = results_df['score'].quantile(0.90)  # Top 10% based on actual probability distribution\n",
    "results_df['prediction'] = (results_df['score'] >= threshold).astype(int)\n",
    "\n",
    "# Compute precision score \n",
    "precision = precision_score(y_test, results_df['prediction'])\n",
    "\n",
    "# Output results\n",
    "print(f\"Precision for top 10%: {precision}\")\n",
    "print(results_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b34abd-26d7-41ee-946b-7e67def9d6de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#importance = rf.feature_importances_\n",
    "#plt.figure(figsize=(12, 10))  # Increase figure size for clarity\n",
    "#plt.barh(X_train.columns, importance)  # Plot feature importance\n",
    "#plt.xticks(rotation=45, fontsize=10)  # Rotate text to prevent overlap\n",
    "#plt.ylabel(\"Features\")  # Label for Y-axis\n",
    "#plt.xlabel(\"Importance Score\")  # Label for X-axis\n",
    "#plt.title(\"Feature Importance\")  # Add a meaningful title\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "#top_features = pd.Series(importance, index=X_train.columns).nlargest(20)  # Show top 20 features\n",
    "#top_features.plot(kind='barh', figsize=(12, 8))\n",
    "#plt.title(\"Top 20 Most Important Features\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c00fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Retrieve model coefficients\n",
    "logistic_coef = model_pipeline.named_steps['model'].coef_[0]\n",
    "\n",
    "# Retrieve feature names after transformation\n",
    "feature_names = model_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "coef_df = pd.DataFrame({'Feature': feature_names, 'Importance': logistic_coef})\n",
    "coef_df = coef_df.sort_values(by='Importance', ascending=False)  # Sort by importance\n",
    "\n",
    "# Display top features\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(coef_df['Feature'].head(20), coef_df['Importance'].head(20))  # Show top 20 features\n",
    "plt.xlabel(\"Coefficient Value\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.title(\"Top 20 Most Important Features in Logistic Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05919f6-f145-4437-af0e-43b57b6c3a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
