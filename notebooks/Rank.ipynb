{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407e5c08-0974-4c0e-aa4d-1137d57e7db0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Step 1: Load and preprocess data\n",
    "outcomes = pd.read_csv('outcomes.csv')\n",
    "projects = pd.read_csv('projects.csv')\n",
    "donations = pd.read_csv('donations.csv')\n",
    "\n",
    "# Safely convert 'donation_timestamp' to datetime with mixed format handling\n",
    "donations['donation_timestamp'] = pd.to_datetime(\n",
    "    donations['donation_timestamp'], \n",
    "    errors='coerce'  # Coerce invalid formats to NaT\n",
    ")\n",
    "# Optionally, drop rows with invalid timestamps\n",
    "donations = donations.dropna(subset=['donation_timestamp'])\n",
    "\n",
    "# Map 't' → 1 and 'f' → 0 in 'fully_funded'\n",
    "outcomes['fully_funded'] = outcomes['fully_funded'].map({'t': 1, 'f': 0})\n",
    "outcomes['not_fully_funded'] = outcomes['fully_funded'].apply(lambda x: 0 if x == 1 else 1)\n",
    "\n",
    "# Confirm the conversion\n",
    "print(outcomes['not_fully_funded'].value_counts())\n",
    "print(outcomes[['projectid','is_exciting', 'not_fully_funded']].head())\n",
    "\n",
    "\n",
    "chunk_size = 5000  # Example chunk size\n",
    "result_chunks = []\n",
    "for start_row in range(0, len(projects), chunk_size):\n",
    "    chunk = projects.iloc[start_row:start_row + chunk_size]\n",
    "    merged_chunk = chunk.merge(outcomes, on='projectid', how='inner').merge(\n",
    "        donations[['projectid', 'donation_timestamp', 'donation_total']], on='projectid', how='inner'\n",
    "    )\n",
    "    result_chunks.append(merged_chunk)\n",
    "\n",
    "# Combine all chunks into a single DataFrame\n",
    "data = pd.concat(result_chunks, ignore_index=True)\n",
    "\n",
    "# Filter by date\n",
    "data = data[data['donation_timestamp'] >= '2010-01-01']\n",
    "\n",
    "# Add interaction features\n",
    "data['subject_resource_interaction'] = data['primary_focus_subject'] + '_' + data['resource_type']\n",
    "data['state_poverty_interaction'] = data['school_state'] + '_' + data['poverty_level']\n",
    "data['donation_per_student'] = data['donation_total'] / (data['students_reached'] + 1)  # Avoid division by zero\n",
    "data['state_resource_interaction'] = data['school_state'] + '_' + data['resource_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dfba26-34cc-46e1-9eb1-cfc8835c0193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Minimal feature matrix\n",
    "features = [\n",
    "    'primary_focus_subject', \n",
    "    'primary_focus_area',\n",
    "    'school_state', \n",
    "    'resource_type', \n",
    "    'poverty_level',\n",
    "    'students_reached',\n",
    "    'donation_total',\n",
    "    'subject_resource_interaction',\n",
    "    'state_poverty_interaction',\n",
    "    'donation_per_student',\n",
    "    'state_resource_interaction'\n",
    "]\n",
    "\n",
    "X_sample = pd.get_dummies(data[features], drop_first=True, dtype='uint8')\n",
    "y_sample = data['not_fully_funded']\n",
    "\n",
    "# Step 3: Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, stratify=y_sample, random_state=42)\n",
    "\n",
    "# Step 4: Train model and predict probabilities\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=15, can_jobs=-1, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_proba = rf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1558d74-bf03-4908-b5d2-998fb988a760",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 5: Rank probabilities and calculate precision\n",
    "results_df = pd.DataFrame({\n",
    "    'projectid': data.loc[X_test.index, 'projectid'], # Match project ID from data_sample\n",
    "    'score': y_proba # Predicted probability of not getting funded\n",
    "})\n",
    "# Sort by score in descending order\n",
    "results_df = results_df.sort_values(by='score', ascending=False)\n",
    "\n",
    "# Assign rank based on score order \n",
    "results_df['rank'] = results_df['score'].rank(method='first', ascending=False)\n",
    "\n",
    "# Label top 10% as needing review \n",
    "threshold = results_df['score'].quantile(0.90)  # Top 10% based on actual probability distribution\n",
    "results_df['prediction'] = (results_df['score'] >= threshold).astype(int)\n",
    "\n",
    "# Compute precision score \n",
    "precision = precision_score(y_test, results_df['prediction'])\n",
    "\n",
    "# Output results\n",
    "print(f\"Precision for top 10%: {precision}\")\n",
    "print(results_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b34abd-26d7-41ee-946b-7e67def9d6de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#importance = rf.feature_importances_\n",
    "#plt.figure(figsize=(12, 10))  # Increase figure size for clarity\n",
    "#plt.barh(X_train.columns, importance)  # Plot feature importance\n",
    "#plt.xticks(rotation=45, fontsize=10)  # Rotate text to prevent overlap\n",
    "#plt.ylabel(\"Features\")  # Label for Y-axis\n",
    "#plt.xlabel(\"Importance Score\")  # Label for X-axis\n",
    "#plt.title(\"Feature Importance\")  # Add a meaningful title\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "#top_features = pd.Series(importance, index=X_train.columns).nlargest(20)  # Show top 20 features\n",
    "#top_features.plot(kind='barh', figsize=(12, 8))\n",
    "#plt.title(\"Top 20 Most Important Features\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05919f6-f145-4437-af0e-43b57b6c3a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
